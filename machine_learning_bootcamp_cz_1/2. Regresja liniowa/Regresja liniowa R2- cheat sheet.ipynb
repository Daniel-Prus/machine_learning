{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5919484",
   "metadata": {},
   "source": [
    "#### 1. Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df, y='coef', width=800, title='Dopasowanie: coefficient')# tworzenie losowego zbioru danych z sklearn\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# model regresji liniowej\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# sprawdzanie score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3b0ad",
   "metadata": {},
   "source": [
    "#### 2. Przygotowanie danych losowych z sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "data, target = make_regression(n_samples=100, n_features=1, n_targets=1, noise=30.0, random_state=42)\n",
    "\n",
    "print(f'data shape: {data.shape}')\n",
    "print(f'target shape: {target.shape}')\n",
    "\n",
    "\"\"\"\n",
    "n_samples - liczba próbek\n",
    "\n",
    "n_features, n_targets - liczba zmiennych x i target\n",
    "\n",
    "noise - rozrzut danych\n",
    "\n",
    "random_state - ziarnolosowe\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e99913",
   "metadata": {},
   "source": [
    "#### 3. Wizualizacja danych i modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title('Regresja liniowa')\n",
    "plt.xlabel('x - variable(predictor/idependent variable)')\n",
    "plt.ylabel('y - variable(response/dependent variable)')\n",
    "plt.scatter (data, target, label='cecha x')\n",
    "plt.plot(data, y_pred, color='red', label='model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wizualizacja train i test - parametr alpha = 0.5 - sprawia, ze kropki są prześwitujące\n",
    "\n",
    "plt.figure (figsize=(8,6))\n",
    "plt.title('Regresja liniowa - train vs test')\n",
    "plt.xlabel('predictor')\n",
    "plt.ylabel('target')\n",
    "plt.scatter(X_train, y_train, color='grey', alpha=0.5, label='train')\n",
    "plt.scatter(X_test, y_test, color='yellow', alpha=0.5, label='test')\n",
    "plt.plot(X_train, reg.intercept_ + reg.coef_[0] * X_train, color='red', label='model' )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223947d",
   "metadata": {},
   "source": [
    "#### 4. Równanie normalne\n",
    "\n",
    "Regresja liniowa w $R^2$:\n",
    "$$Y = w_0 + w_1X_1$$\n",
    "$$Y = W^TX$$\n",
    "gdzie: $$W= \\left[\\begin{matrix}w_0\\\\w_1\\end{matrix}\\right]$$ $$ X= \\left[\\begin{matrix}1\\\\X_1\\end{matrix}\\right] $$ stąd $$ W^T= \\left[\\begin{matrix}w_0&w_1\\end{matrix}\\right] $$    \n",
    "$$Y = W^TX = \\left[\\begin{matrix}w_0&w_1\\end{matrix}\\right] \\cdot  \\left[\\begin{matrix}1\\\\X_1\\end{matrix}\\right] = w_0 + w_1X_1$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Równanie normalne - równanie pozwalające obliczyć minimum funkcji straty (o ile istnieje)\n",
    "\n",
    "$$W = (X^TX)^{-1}(X^TY)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426c1ae",
   "metadata": {},
   "source": [
    "#### - numpy i pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddfb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([1, 2, 3, 4, 5, 6])\n",
    "Y = np.array([3000, 3250, 3500, 3750, 4000, 4250])\n",
    "m = len(X1)\n",
    "\n",
    "# zmiana kształtu tablicy\n",
    "X1 = X1.reshape(m,1)\n",
    "\n",
    "# tworzenie bias\n",
    "bias = np.ones((m,1))\n",
    "\n",
    "# łączenie wzdłuż kolumn pierwszy bias/drugi x_true\n",
    "X = np.append(bias, X1,axis=1)\n",
    "\n",
    "# transponowanie X\n",
    "X.T\n",
    "\n",
    "# mnożenie macierzy\n",
    "np.dot(X.T,X)\n",
    "\n",
    "# obliczenie lewej strony równania - (XT*X)-1 - obliczanie macierzy odwrotnej (podniesienie do potęgi - 1)\n",
    "L = np.linalg.inv(np.dot(X.T,X))\n",
    "\n",
    "# obliczanie prwej strony - transponowane X * Y\n",
    "P = np.dot(X.T, Y)\n",
    "\n",
    "# finałowe mnożenie macierzy - lewej i prawej strony\n",
    "W = np.dot(L,P)\n",
    "\n",
    "#wynik = array([2750.,  250.]) ( Y = 2750 + 250*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b3b3d",
   "metadata": {},
   "source": [
    "#### -  sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44001b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tutaj nie musimy łączyć macierzu 1 z X1, sklearn robi to autmatycznie\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.fit(X1, Y)\n",
    "\n",
    "print(regression.intercept_) # w0 - przecięcie\n",
    "print(regression.coef_[0]) # coefficient - współczynnik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04481d6f",
   "metadata": {},
   "source": [
    "#### 5. Metoda spadku gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4511d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transponowanie\n",
    "X1 = X1.reshape((6,1))\n",
    "Y = Y.reshape((-1,1))\n",
    "\n",
    "#bias\n",
    "bias = np.ones((6,1))\n",
    "X = np.append(bias, X1, axis=1)\n",
    "\n",
    "#Inicjalizacja losowych parametrów\n",
    "# parametr 'eta' - wskaźnik uczenia - o tyle będziemy mnożyć wartość gradientu - o taką wartość będą wykonywane kroki\n",
    "eta = 0.01\n",
    "\n",
    "# zainicjowanie losowe wagi - macierz 2 na 1, jest to punkt startowy w0 i w1\n",
    "weights = np.random.randn (2,1)\n",
    "\n",
    "\n",
    "# metoda\n",
    "\n",
    "# tworzenie list - intercept (punktów przecięcia) - w0 , coef (coefficient) - współczynnik kierunkowy w1:\n",
    "\n",
    "intercept =[]\n",
    "coef = []\n",
    "\n",
    "# wzór z lekcji\n",
    "\n",
    "for i in range(3000):\n",
    "    gradient = (2 / m) * X.T.dot(X.dot(weights) - Y)   # wzór \n",
    "    weights = weights - eta * gradient\n",
    "    intercept.append(weights[0][0])\n",
    "    coef.append(weights[1][0])\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7cfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja\n",
    "\n",
    "df = pd.DataFrame(data={'intercept': intercept, 'coef': coef})\n",
    "\n",
    "px.line(df, y='intercept', width=800, title='Dopasowanie: intercept')\n",
    "px.line(df, y='coef', width=800, title='Dopasowanie: coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951ec96",
   "metadata": {},
   "source": [
    "#### 5. Regresja liniowa przy użyciu sklearn \n",
    "\n",
    "\n",
    "\n",
    "$Y = w_0 + w_1X_1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wymaga podziału zbiorów na treningowy i testowy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target,  test_size=0.25)\n",
    "\n",
    "print (f'data shape: {data.shape}')\n",
    "print (f'target shape: {target.shape}')\n",
    "print (f'X_train shape: {X_train.shape}')\n",
    "print (f'X_test shape: {X_test.shape}')\n",
    "print (f'y_train shape: {y_train.shape}')\n",
    "print (f'y_test shape: {y_test.shape}\\n')\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit (X_train, y_train)\n",
    "\n",
    "reg.score(X_train, y_train)\n",
    "\n",
    "reg.coef_\n",
    "\n",
    "reg.intercept_\n",
    "\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# metoda fit dopasowuje model liniowy do danych\n",
    "\n",
    "regressor.fit(data, target)\n",
    "\n",
    "\n",
    "# metoda score() dokonuje oceny modelu na przekazanych danych (wynik R2 score) \n",
    "\n",
    "# im bliżej jedynki tym model jest lepiej dopasowany\n",
    "\n",
    "regressor.score(data, target)\n",
    "\n",
    "\n",
    "# metoda predict() dokonuje predykcji na podstawie modelu\n",
    "\n",
    "y_pred = regressor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad09250",
   "metadata": {},
   "source": [
    "##### - współczynnik R2 score:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae323a",
   "metadata": {},
   "source": [
    "Współczynnik $R^2$ jest zdefiniowany jako $1 - \\frac{u}{v}$, gdzie $u$ jest określone wzorem\n",
    "\n",
    "((y_true - y_pred) ** 2).sum()\n",
    "\n",
    "\n",
    "**oraz $v$ jako**\n",
    "\n",
    "((y_true - y_true.mean()) ** 2).sum()\n",
    "\n",
    "**Czyli:**\n",
    "\n",
    "1 - (((y_true - y_pred) ** 2).sum()) / (((y_true - y_true.mean()) ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyliczenie r2 za pomocą numpy i pandas:\n",
    "\n",
    "r2 = 1 - (((target - y_pred) ** 2).sum()) / (((target - target.mean()) ** 2).sum())\n",
    "r2\n",
    "\n",
    "# r2 z skleran LinearRegression\n",
    "\n",
    "regressor.score(data, target) == r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147370c5",
   "metadata": {},
   "source": [
    "###### - współczynniki w0 (intercept) i w1 (coef)\n",
    "\n",
    "$$Y = w_0 + w_1X_1$$\n",
    "Postać modelu: $$Y = 3.495 + 49.83 \\cdot X_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21203224",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.coef_ # w1\n",
    "\n",
    "regressor.intercept_ # w0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841edef",
   "metadata": {},
   "source": [
    "#### 6. Predykcja na podstawie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d16ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# tworzymy data frame z predykcji:\n",
    "\n",
    "predictions = pd.DataFrame(data = {'y_true': y_test, 'y_pred': y_pred})\n",
    "\n",
    "\"\"\"\n",
    "y_pred - tworzymy na podstawie X_test (testowy zbiór data bez targetu)\n",
    "\n",
    "predictions(df) - y_true = y_test - target ze zbioru testowego\n",
    "predictions(df) - y_pred - stworzona predykcja y na zbiorze danych testowych x\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# dołączenie serii z błędami - y_true - y_pred\n",
    "\n",
    "# - tabela błędów\n",
    "\n",
    "predictions['errors'] = predictions['y_true'] - predictions.y_pred\n",
    "\n",
    "# - histogram do oceny błędów - powinien być rozkład normalny, bądź zbliżony do normalnego\n",
    "_ = predictions['errors'].plot(kind='hist', bins=50, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd9810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
