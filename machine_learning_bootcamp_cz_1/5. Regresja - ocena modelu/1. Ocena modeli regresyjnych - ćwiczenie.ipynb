{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4780b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38dcc5",
   "metadata": {},
   "source": [
    "### 1. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = 100 + 20 * np.random.randn(50)\n",
    "y_pred = y_true + 10 * np.random.randn(50)\n",
    "results = pd.DataFrame(data={'y_true': y_true, 'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data={'y_true': y_true, 'y_pred': y_pred})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896947fc",
   "metadata": {},
   "source": [
    "#### - obliczenie różnicy błędów i kwadratu błędu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['error'] = results['y_true'] - results['y_pred']\n",
    "results['error_squared'] = results['error'] ** 2\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd631279",
   "metadata": {},
   "source": [
    "#### - obliczanie MAE, MSE, RMSE, ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974199b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (f\"MAE - Mean absolute error: {np.abs(results['error']).sum() / len(results)}\")\n",
    "print (f\"MSE - Mean squared error: {results['error_squared'].sum() / len(results)}\")\n",
    "print (f\"RMSE - Root mean squared error: {np.sqrt(results['error_squared'].sum() / len(results))}\")\n",
    "print (f\"ME - Max error: {max(abs(results['error']))} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3de2ce",
   "metadata": {},
   "source": [
    "### 2. Interpretacja graficzna modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_results(y_true, y_pred): \n",
    "\n",
    "    results = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "    min = results[['y_true', 'y_pred']].min().min()\n",
    "    max = results[['y_true', 'y_pred']].max().max()\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter(x=results['y_true'], y=results['y_pred'], mode='markers'),\n",
    "                    go.Scatter(x=[min, max], y=[min, max])],\n",
    "                    layout=go.Layout(showlegend=False, width=800,\n",
    "                                     xaxis_title='y_true', \n",
    "                                     yaxis_title='y_pred',\n",
    "                                     title='Regresja: y_true vs. y_pred'))\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdde09",
   "metadata": {},
   "source": [
    "### 3. Histogram błędów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = 100 + 20 * np.random.randn(1000)\n",
    "y_pred = y_true + 10 * np.random.randn(1000)\n",
    "\n",
    "results = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "results['error'] = results['y_true'] - results['y_pred']\n",
    "\n",
    "px.histogram(results, x='error', nbins=50, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32318b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=results['error'].sort_values(), bins=50,);\n",
    "plt.xlabel('error')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf37d13",
   "metadata": {},
   "source": [
    "### 4. Współczynniki ze sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17134c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275b78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = 100 + 20 * np.random.randn(1000)\n",
    "y_pred = y_true + 10 * np.random.randn(1000)\n",
    "results = pd.DataFrame(data={'y_true': y_true, 'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a46014a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "max_err = max_error(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4430148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame(data={'mae':mae, 'mse':mse, 'rmse':rmse, 'r2_score': r2, 'max_error': max_err}, index=['model scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a95c516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model scores</th>\n",
       "      <td>7.916481</td>\n",
       "      <td>99.893809</td>\n",
       "      <td>9.994689</td>\n",
       "      <td>0.739291</td>\n",
       "      <td>31.931076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mae        mse      rmse  r2_score  max_error\n",
       "model scores  7.916481  99.893809  9.994689  0.739291  31.931076"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2737652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.89380919231107"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bca3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
